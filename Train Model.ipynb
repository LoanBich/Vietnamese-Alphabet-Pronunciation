{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slime/Workspace/Vietnamese-Alphabet-Pronunciation/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/slime/Workspace/Vietnamese-Alphabet-Pronunciation/.venv/lib/python3.10/site-packages/transformers/configuration_utils.py:311: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from src.dataset import VietAlphabetDataset, id2label\n",
    "from src.feature_extractor import wav2vec2\n",
    "from src.models import fit_model, save_model\n",
    "\n",
    "dataset = VietAlphabetDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m,\n",
       "       \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m,\n",
       "       \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m,\n",
       "       \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m6\u001b[0m,\n",
       "       \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m,\n",
       "       \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m,\n",
       "       \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vectors = []\n",
    "labels = []\n",
    "\n",
    "for waveform, label in dataset:\n",
    "    feat = wav2vec2(waveform)\n",
    "\n",
    "    feature_vectors.append(feat)\n",
    "    labels.append(label)\n",
    "\n",
    "feature_vectors = pad_sequence(feature_vectors, batch_first=True).numpy()\n",
    "labels = np.asarray(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m141\u001b[0m, \u001b[1;36m86\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m141\u001b[0m,\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vectors.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.12676048\n",
      "Iteration 2, loss = 2.12635136\n",
      "Iteration 3, loss = 2.12577510\n",
      "Iteration 4, loss = 2.12505412\n",
      "Iteration 5, loss = 2.12420917\n",
      "Iteration 6, loss = 2.12332129\n",
      "Iteration 7, loss = 2.12238693\n",
      "Iteration 8, loss = 2.12133646\n",
      "Iteration 9, loss = 2.12021279\n",
      "Iteration 10, loss = 2.11907005\n",
      "Iteration 11, loss = 2.11792207\n",
      "Iteration 12, loss = 2.11675930\n",
      "Iteration 13, loss = 2.11559319\n",
      "Iteration 14, loss = 2.11443567\n",
      "Iteration 15, loss = 2.11328745\n",
      "Iteration 16, loss = 2.11215115\n",
      "Iteration 17, loss = 2.11103344\n",
      "Iteration 18, loss = 2.10993648\n",
      "Iteration 19, loss = 2.10886407\n",
      "Iteration 20, loss = 2.10781717\n",
      "Iteration 21, loss = 2.10679579\n",
      "Iteration 22, loss = 2.10580111\n",
      "Iteration 23, loss = 2.10483193\n",
      "Iteration 24, loss = 2.10389066\n",
      "Iteration 25, loss = 2.10297585\n",
      "Iteration 26, loss = 2.10208583\n",
      "Iteration 27, loss = 2.10123873\n",
      "Iteration 28, loss = 2.10044050\n",
      "Iteration 29, loss = 2.09971404\n",
      "Iteration 30, loss = 2.09901619\n",
      "Iteration 31, loss = 2.09831381\n",
      "Iteration 32, loss = 2.09761095\n",
      "Iteration 33, loss = 2.09691048\n",
      "Iteration 34, loss = 2.09621930\n",
      "Iteration 35, loss = 2.09557271\n",
      "Iteration 36, loss = 2.09494948\n",
      "Iteration 37, loss = 2.09435439\n",
      "Iteration 38, loss = 2.09377432\n",
      "Iteration 39, loss = 2.09320521\n",
      "Iteration 40, loss = 2.09264708\n",
      "Iteration 41, loss = 2.09210038\n",
      "Iteration 42, loss = 2.09157228\n",
      "Iteration 43, loss = 2.09106088\n",
      "Iteration 44, loss = 2.09056306\n",
      "Iteration 45, loss = 2.09008098\n",
      "Iteration 46, loss = 2.08961296\n",
      "Iteration 47, loss = 2.08916068\n",
      "Iteration 48, loss = 2.08871818\n",
      "Iteration 49, loss = 2.08828974\n",
      "Iteration 50, loss = 2.08787489\n",
      "Iteration 51, loss = 2.08747149\n",
      "Iteration 52, loss = 2.08707976\n",
      "Iteration 53, loss = 2.08670020\n",
      "Iteration 54, loss = 2.08633065\n",
      "Iteration 55, loss = 2.08597302\n",
      "Iteration 56, loss = 2.08562613\n",
      "Iteration 57, loss = 2.08528829\n",
      "Iteration 58, loss = 2.08496237\n",
      "Iteration 59, loss = 2.08464456\n",
      "Iteration 60, loss = 2.08433914\n",
      "Iteration 61, loss = 2.08404136\n",
      "Iteration 62, loss = 2.08375239\n",
      "Iteration 63, loss = 2.08347344\n",
      "Iteration 64, loss = 2.08320045\n",
      "Iteration 65, loss = 2.08293867\n",
      "Iteration 66, loss = 2.08268332\n",
      "Iteration 67, loss = 2.08243585\n",
      "Iteration 68, loss = 2.08219576\n",
      "Iteration 69, loss = 2.08196282\n",
      "Iteration 70, loss = 2.08173680\n",
      "Iteration 71, loss = 2.08151793\n",
      "Iteration 72, loss = 2.08130622\n",
      "Iteration 73, loss = 2.08110094\n",
      "Iteration 74, loss = 2.08090234\n",
      "Iteration 75, loss = 2.08070970\n",
      "Iteration 76, loss = 2.08052230\n",
      "Iteration 77, loss = 2.08034134\n",
      "Iteration 78, loss = 2.08016586\n",
      "Iteration 79, loss = 2.07999539\n",
      "Iteration 80, loss = 2.07983065\n",
      "Iteration 81, loss = 2.07966995\n",
      "Iteration 82, loss = 2.07951474\n",
      "Iteration 83, loss = 2.07936406\n",
      "Iteration 84, loss = 2.07921791\n",
      "Iteration 85, loss = 2.07907653\n",
      "Iteration 86, loss = 2.07893920\n",
      "Iteration 87, loss = 2.07880592\n",
      "Iteration 88, loss = 2.07867646\n",
      "Iteration 89, loss = 2.07855082\n",
      "Iteration 90, loss = 2.07842922\n",
      "Iteration 91, loss = 2.07831097\n",
      "Iteration 92, loss = 2.07819557\n",
      "Iteration 93, loss = 2.07808352\n",
      "Iteration 94, loss = 2.07797384\n",
      "Iteration 95, loss = 2.07786775\n",
      "Iteration 96, loss = 2.07776594\n",
      "Iteration 97, loss = 2.07766747\n",
      "Iteration 98, loss = 2.07757068\n",
      "Iteration 99, loss = 2.07747746\n",
      "Iteration 100, loss = 2.07738638\n",
      "Iteration 101, loss = 2.07729840\n",
      "Iteration 102, loss = 2.07721376\n",
      "Iteration 103, loss = 2.07712984\n",
      "Iteration 104, loss = 2.07704902\n",
      "Iteration 105, loss = 2.07697082\n",
      "Iteration 106, loss = 2.07689428\n",
      "Iteration 107, loss = 2.07681990\n",
      "Iteration 108, loss = 2.07674766\n",
      "Iteration 109, loss = 2.07667732\n",
      "Iteration 110, loss = 2.07660913\n",
      "Iteration 111, loss = 2.07654285\n",
      "Iteration 112, loss = 2.07647777\n",
      "Iteration 113, loss = 2.07641459\n",
      "Iteration 114, loss = 2.07635403\n",
      "Iteration 115, loss = 2.07629395\n",
      "Iteration 116, loss = 2.07623625\n",
      "Iteration 117, loss = 2.07617974\n",
      "Iteration 118, loss = 2.07612491\n",
      "Iteration 119, loss = 2.07607150\n",
      "Iteration 120, loss = 2.07601953\n",
      "Iteration 121, loss = 2.07596970\n",
      "Iteration 122, loss = 2.07591987\n",
      "Iteration 123, loss = 2.07587218\n",
      "Iteration 124, loss = 2.07582521\n",
      "Iteration 125, loss = 2.07577944\n",
      "Iteration 126, loss = 2.07573509\n",
      "Iteration 127, loss = 2.07569218\n",
      "Iteration 128, loss = 2.07564998\n",
      "Iteration 129, loss = 2.07560849\n",
      "Iteration 130, loss = 2.07556820\n",
      "Iteration 131, loss = 2.07552886\n",
      "Iteration 132, loss = 2.07549000\n",
      "Iteration 133, loss = 2.07545233\n",
      "Iteration 134, loss = 2.07541561\n",
      "Iteration 135, loss = 2.07537937\n",
      "Iteration 136, loss = 2.07534432\n",
      "Iteration 137, loss = 2.07530951\n",
      "Iteration 138, loss = 2.07527566\n",
      "Iteration 139, loss = 2.07524228\n",
      "Iteration 140, loss = 2.07521009\n",
      "Iteration 141, loss = 2.07517791\n",
      "Iteration 142, loss = 2.07514644\n",
      "Iteration 143, loss = 2.07511473\n",
      "Iteration 144, loss = 2.07508445\n",
      "Iteration 145, loss = 2.07505488\n",
      "Iteration 146, loss = 2.07502580\n",
      "Iteration 147, loss = 2.07499695\n",
      "Iteration 148, loss = 2.07496881\n",
      "Iteration 149, loss = 2.07494116\n",
      "Iteration 150, loss = 2.07491422\n",
      "Iteration 151, loss = 2.07488775\n",
      "Iteration 152, loss = 2.07486153\n",
      "Iteration 153, loss = 2.07483554\n",
      "Iteration 154, loss = 2.07481027\n",
      "Iteration 155, loss = 2.07478523\n",
      "Iteration 156, loss = 2.07476044\n",
      "Iteration 157, loss = 2.07473612\n",
      "Iteration 158, loss = 2.07471228\n",
      "Iteration 159, loss = 2.07468891\n",
      "Iteration 160, loss = 2.07466555\n",
      "Iteration 161, loss = 2.07464266\n",
      "Iteration 162, loss = 2.07462001\n",
      "Iteration 163, loss = 2.07459784\n",
      "Iteration 164, loss = 2.07457566\n",
      "Iteration 165, loss = 2.07455397\n",
      "Iteration 166, loss = 2.07453251\n",
      "Iteration 167, loss = 2.07451105\n",
      "Iteration 168, loss = 2.07448959\n",
      "Iteration 169, loss = 2.07446885\n",
      "Iteration 170, loss = 2.07444835\n",
      "Iteration 171, loss = 2.07442737\n",
      "Iteration 172, loss = 2.07440519\n",
      "Iteration 173, loss = 2.07438397\n",
      "Iteration 174, loss = 2.07436275\n",
      "Iteration 175, loss = 2.07434344\n",
      "Iteration 176, loss = 2.07432294\n",
      "Iteration 177, loss = 2.07430339\n",
      "Iteration 178, loss = 2.07428408\n",
      "Iteration 179, loss = 2.07426453\n",
      "Iteration 180, loss = 2.07424569\n",
      "Iteration 181, loss = 2.07422686\n",
      "Iteration 182, loss = 2.07420826\n",
      "Iteration 183, loss = 2.07418942\n",
      "Iteration 184, loss = 2.07417107\n",
      "Iteration 185, loss = 2.07415247\n",
      "Iteration 186, loss = 2.07413411\n",
      "Iteration 187, loss = 2.07411551\n",
      "Iteration 188, loss = 2.07409739\n",
      "Iteration 189, loss = 2.07407904\n",
      "Iteration 190, loss = 2.07406068\n",
      "Iteration 191, loss = 2.07404113\n",
      "Iteration 192, loss = 2.07401896\n",
      "Iteration 193, loss = 2.07399797\n",
      "Iteration 194, loss = 2.07397985\n",
      "Iteration 195, loss = 2.07396150\n",
      "Iteration 196, loss = 2.07394290\n",
      "Iteration 197, loss = 2.07392478\n",
      "Iteration 198, loss = 2.07390666\n",
      "Iteration 199, loss = 2.07388830\n",
      "Iteration 200, loss = 2.07387018\n",
      "Iteration 201, loss = 2.07385230\n",
      "Iteration 202, loss = 2.07383442\n",
      "Iteration 203, loss = 2.07381606\n",
      "Iteration 204, loss = 2.07379770\n",
      "Iteration 205, loss = 2.07377958\n",
      "Iteration 206, loss = 2.07376146\n",
      "Iteration 207, loss = 2.07374334\n",
      "Iteration 208, loss = 2.07372451\n",
      "Iteration 209, loss = 2.07370687\n",
      "Iteration 210, loss = 2.07368875\n",
      "Iteration 211, loss = 2.07367039\n",
      "Iteration 212, loss = 2.07365179\n",
      "Iteration 213, loss = 2.07363391\n",
      "Iteration 214, loss = 2.07361603\n",
      "Iteration 215, loss = 2.07359767\n",
      "Iteration 216, loss = 2.07357883\n",
      "Iteration 217, loss = 2.07356048\n",
      "Iteration 218, loss = 2.07354236\n",
      "Iteration 219, loss = 2.07352376\n",
      "Iteration 220, loss = 2.07350516\n",
      "Iteration 221, loss = 2.07348704\n",
      "Iteration 222, loss = 2.07346845\n",
      "Iteration 223, loss = 2.07345033\n",
      "Iteration 224, loss = 2.07343149\n",
      "Iteration 225, loss = 2.07341290\n",
      "Iteration 226, loss = 2.07339430\n",
      "Iteration 227, loss = 2.07337570\n",
      "Iteration 228, loss = 2.07335711\n",
      "Iteration 229, loss = 2.07333851\n",
      "Iteration 230, loss = 2.07331967\n",
      "Iteration 231, loss = 2.07330108\n",
      "Iteration 232, loss = 2.07328200\n",
      "Iteration 233, loss = 2.07326317\n",
      "Iteration 234, loss = 2.07324433\n",
      "Iteration 235, loss = 2.07322502\n",
      "Iteration 236, loss = 2.07320571\n",
      "Iteration 237, loss = 2.07318711\n",
      "Iteration 238, loss = 2.07316732\n",
      "Iteration 239, loss = 2.07314825\n",
      "Iteration 240, loss = 2.07312870\n",
      "Iteration 241, loss = 2.07310939\n",
      "Iteration 242, loss = 2.07308960\n",
      "Iteration 243, loss = 2.07307005\n",
      "Iteration 244, loss = 2.07305026\n",
      "Iteration 245, loss = 2.07303023\n",
      "Iteration 246, loss = 2.07301092\n",
      "Iteration 247, loss = 2.07299042\n",
      "Iteration 248, loss = 2.07297063\n",
      "Iteration 249, loss = 2.07295060\n",
      "Iteration 250, loss = 2.07293010\n",
      "Iteration 251, loss = 2.07290983\n",
      "Iteration 252, loss = 2.07288933\n",
      "Iteration 253, loss = 2.07286882\n",
      "Iteration 254, loss = 2.07284832\n",
      "Iteration 255, loss = 2.07282805\n",
      "Iteration 256, loss = 2.07280707\n",
      "Iteration 257, loss = 2.07278609\n",
      "Iteration 258, loss = 2.07276583\n",
      "Iteration 259, loss = 2.07274461\n",
      "Iteration 260, loss = 2.07272339\n",
      "Iteration 261, loss = 2.07270265\n",
      "Iteration 262, loss = 2.07268071\n",
      "Iteration 263, loss = 2.07265925\n",
      "Iteration 264, loss = 2.07263827\n",
      "Iteration 265, loss = 2.07261634\n",
      "Iteration 266, loss = 2.07259440\n",
      "Iteration 267, loss = 2.07257318\n",
      "Iteration 268, loss = 2.07255125\n",
      "Iteration 269, loss = 2.07252955\n",
      "Iteration 270, loss = 2.07250690\n",
      "Iteration 271, loss = 2.07248497\n",
      "Iteration 272, loss = 2.07246232\n",
      "Iteration 273, loss = 2.07244015\n",
      "Iteration 274, loss = 2.07241726\n",
      "Iteration 275, loss = 2.07239485\n",
      "Iteration 276, loss = 2.07237172\n",
      "Iteration 277, loss = 2.07234859\n",
      "Iteration 278, loss = 2.07232571\n",
      "Iteration 279, loss = 2.07230258\n",
      "Iteration 280, loss = 2.07227898\n",
      "Iteration 281, loss = 2.07225633\n",
      "Iteration 282, loss = 2.07223248\n",
      "Iteration 283, loss = 2.07220864\n",
      "Iteration 284, loss = 2.07218456\n",
      "Iteration 285, loss = 2.07216096\n",
      "Iteration 286, loss = 2.07213640\n",
      "Iteration 287, loss = 2.07211208\n",
      "Iteration 288, loss = 2.07208800\n",
      "Iteration 289, loss = 2.07206321\n",
      "Iteration 290, loss = 2.07203865\n",
      "Iteration 291, loss = 2.07201385\n",
      "Iteration 292, loss = 2.07198930\n",
      "Iteration 293, loss = 2.07196403\n",
      "Iteration 294, loss = 2.07193851\n",
      "Iteration 295, loss = 2.07191348\n",
      "Iteration 296, loss = 2.07188797\n",
      "Iteration 297, loss = 2.07186198\n",
      "Iteration 298, loss = 2.07183599\n",
      "Iteration 299, loss = 2.07181001\n",
      "Iteration 300, loss = 2.07178426\n",
      "Iteration 301, loss = 2.07175756\n",
      "Iteration 302, loss = 2.07173133\n",
      "Iteration 303, loss = 2.07170486\n",
      "Iteration 304, loss = 2.07167768\n",
      "Iteration 305, loss = 2.07165051\n",
      "Iteration 306, loss = 2.07162309\n",
      "Iteration 307, loss = 2.07159519\n",
      "Iteration 308, loss = 2.07156706\n",
      "Iteration 309, loss = 2.07153916\n",
      "Iteration 310, loss = 2.07151079\n",
      "Iteration 311, loss = 2.07148242\n",
      "Iteration 312, loss = 2.07145333\n",
      "Iteration 313, loss = 2.07142401\n",
      "Iteration 314, loss = 2.07139540\n",
      "Iteration 315, loss = 2.07136583\n",
      "Iteration 316, loss = 2.07133627\n",
      "Iteration 317, loss = 2.07130694\n",
      "Iteration 318, loss = 2.07127762\n",
      "Iteration 319, loss = 2.07124782\n",
      "Iteration 320, loss = 2.07121801\n",
      "Iteration 321, loss = 2.07118869\n",
      "Iteration 322, loss = 2.07115865\n",
      "Iteration 323, loss = 2.07112813\n",
      "Iteration 324, loss = 2.07109761\n",
      "Iteration 325, loss = 2.07106757\n",
      "Iteration 326, loss = 2.07103682\n",
      "Iteration 327, loss = 2.07100582\n",
      "Iteration 328, loss = 2.07097507\n",
      "Iteration 329, loss = 2.07094407\n",
      "Iteration 330, loss = 2.07091236\n",
      "Iteration 331, loss = 2.07088089\n",
      "Iteration 332, loss = 2.07084894\n",
      "Iteration 333, loss = 2.07081747\n",
      "Iteration 334, loss = 2.07078505\n",
      "Iteration 335, loss = 2.07075238\n",
      "Iteration 336, loss = 2.07071972\n",
      "Iteration 337, loss = 2.07068658\n",
      "Iteration 338, loss = 2.07065296\n",
      "Iteration 339, loss = 2.07061982\n",
      "Iteration 340, loss = 2.07058620\n",
      "Iteration 341, loss = 2.07055235\n",
      "Iteration 342, loss = 2.07051778\n",
      "Iteration 343, loss = 2.07048345\n",
      "Iteration 344, loss = 2.07044840\n",
      "Iteration 345, loss = 2.07041359\n",
      "Iteration 346, loss = 2.07037878\n",
      "Iteration 347, loss = 2.07034373\n",
      "Iteration 348, loss = 2.07030821\n",
      "Iteration 349, loss = 2.07027221\n",
      "Iteration 350, loss = 2.07023668\n",
      "Iteration 351, loss = 2.07020044\n",
      "Iteration 352, loss = 2.07016373\n",
      "Iteration 353, loss = 2.07012773\n",
      "Iteration 354, loss = 2.07009077\n",
      "Iteration 355, loss = 2.07005334\n",
      "Iteration 356, loss = 2.07001638\n",
      "Iteration 357, loss = 2.06997824\n",
      "Iteration 358, loss = 2.06994033\n",
      "Iteration 359, loss = 2.06990242\n",
      "Iteration 360, loss = 2.06986380\n",
      "Iteration 361, loss = 2.06982517\n",
      "Iteration 362, loss = 2.06978607\n",
      "Iteration 363, loss = 2.06974721\n",
      "Iteration 364, loss = 2.06970787\n",
      "Iteration 365, loss = 2.06966805\n",
      "Iteration 366, loss = 2.06962872\n",
      "Iteration 367, loss = 2.06958795\n",
      "Iteration 368, loss = 2.06954789\n",
      "Iteration 369, loss = 2.06950688\n",
      "Iteration 370, loss = 2.06946588\n",
      "Iteration 371, loss = 2.06942463\n",
      "Iteration 372, loss = 2.06938291\n",
      "Iteration 373, loss = 2.06934047\n",
      "Iteration 374, loss = 2.06929874\n",
      "Iteration 375, loss = 2.06925583\n",
      "Iteration 376, loss = 2.06921268\n",
      "Iteration 377, loss = 2.06916976\n",
      "Iteration 378, loss = 2.06912589\n",
      "Iteration 379, loss = 2.06908131\n",
      "Iteration 380, loss = 2.06903791\n",
      "Iteration 381, loss = 2.06899309\n",
      "Iteration 382, loss = 2.06894803\n",
      "Iteration 383, loss = 2.06890321\n",
      "Iteration 384, loss = 2.06885767\n",
      "Iteration 385, loss = 2.06881189\n",
      "Iteration 386, loss = 2.06876707\n",
      "Iteration 387, loss = 2.06872225\n",
      "Iteration 388, loss = 2.06867385\n",
      "Iteration 389, loss = 2.06862617\n",
      "Iteration 390, loss = 2.06857896\n",
      "Iteration 391, loss = 2.06853080\n",
      "Iteration 392, loss = 2.06848240\n",
      "Iteration 393, loss = 2.06843400\n",
      "Iteration 394, loss = 2.06838441\n",
      "Iteration 395, loss = 2.06833529\n",
      "Iteration 396, loss = 2.06828666\n",
      "Iteration 397, loss = 2.06823564\n",
      "Iteration 398, loss = 2.06818533\n",
      "Iteration 399, loss = 2.06813407\n",
      "Iteration 400, loss = 2.06808305\n",
      "Iteration 401, loss = 2.06803107\n",
      "Iteration 402, loss = 2.06797910\n",
      "Iteration 403, loss = 2.06792641\n",
      "Iteration 404, loss = 2.06787348\n",
      "Iteration 405, loss = 2.06782007\n",
      "Iteration 406, loss = 2.06776667\n",
      "Iteration 407, loss = 2.06771207\n",
      "Iteration 408, loss = 2.06765771\n",
      "Iteration 409, loss = 2.06760240\n",
      "Iteration 410, loss = 2.06754732\n",
      "Iteration 411, loss = 2.06749129\n",
      "Iteration 412, loss = 2.06743503\n",
      "Iteration 413, loss = 2.06737876\n",
      "Iteration 414, loss = 2.06732154\n",
      "Iteration 415, loss = 2.06726432\n",
      "Iteration 416, loss = 2.06720591\n",
      "Iteration 417, loss = 2.06714916\n",
      "Iteration 418, loss = 2.06708956\n",
      "Iteration 419, loss = 2.06703043\n",
      "Iteration 420, loss = 2.06697059\n",
      "Iteration 421, loss = 2.06691003\n",
      "Iteration 422, loss = 2.06685114\n",
      "Iteration 423, loss = 2.06678915\n",
      "Iteration 424, loss = 2.06672764\n",
      "Iteration 425, loss = 2.06666589\n",
      "Iteration 426, loss = 2.06660318\n",
      "Iteration 427, loss = 2.06654072\n",
      "Iteration 428, loss = 2.06647730\n",
      "Iteration 429, loss = 2.06641364\n",
      "Iteration 430, loss = 2.06634903\n",
      "Iteration 431, loss = 2.06628442\n",
      "Iteration 432, loss = 2.06622005\n",
      "Iteration 433, loss = 2.06615329\n",
      "Iteration 434, loss = 2.06608677\n",
      "Iteration 435, loss = 2.06602049\n",
      "Iteration 436, loss = 2.06595278\n",
      "Iteration 437, loss = 2.06588602\n",
      "Iteration 438, loss = 2.06581640\n",
      "Iteration 439, loss = 2.06574655\n",
      "Iteration 440, loss = 2.06567764\n",
      "Iteration 441, loss = 2.06560612\n",
      "Iteration 442, loss = 2.06553602\n",
      "Iteration 443, loss = 2.06546402\n",
      "Iteration 444, loss = 2.06539226\n",
      "Iteration 445, loss = 2.06531978\n",
      "Iteration 446, loss = 2.06524634\n",
      "Iteration 447, loss = 2.06517291\n",
      "Iteration 448, loss = 2.06509876\n",
      "Iteration 449, loss = 2.06502438\n",
      "Iteration 450, loss = 2.06494999\n",
      "Iteration 451, loss = 2.06487489\n",
      "Iteration 452, loss = 2.06479740\n",
      "Iteration 453, loss = 2.06471920\n",
      "Iteration 454, loss = 2.06464100\n",
      "Iteration 455, loss = 2.06456494\n",
      "Iteration 456, loss = 2.06448674\n",
      "Iteration 457, loss = 2.06440473\n",
      "Iteration 458, loss = 2.06432414\n",
      "Iteration 459, loss = 2.06424260\n",
      "Iteration 460, loss = 2.06416130\n",
      "Iteration 461, loss = 2.06407762\n",
      "Iteration 462, loss = 2.06399465\n",
      "Iteration 463, loss = 2.06391191\n",
      "Iteration 464, loss = 2.06382608\n",
      "Iteration 465, loss = 2.06374383\n",
      "Iteration 466, loss = 2.06365824\n",
      "Iteration 467, loss = 2.06356907\n",
      "Iteration 468, loss = 2.06348157\n",
      "Iteration 469, loss = 2.06339359\n",
      "Iteration 470, loss = 2.06330633\n",
      "Iteration 471, loss = 2.06321549\n",
      "Iteration 472, loss = 2.06312466\n",
      "Iteration 473, loss = 2.06303596\n",
      "Iteration 474, loss = 2.06294203\n",
      "Iteration 475, loss = 2.06284976\n",
      "Iteration 476, loss = 2.06275773\n",
      "Iteration 477, loss = 2.06266260\n",
      "Iteration 478, loss = 2.06256843\n",
      "Iteration 479, loss = 2.06247211\n",
      "Iteration 480, loss = 2.06237769\n",
      "Iteration 481, loss = 2.06227970\n",
      "Iteration 482, loss = 2.06218505\n",
      "Iteration 483, loss = 2.06208491\n",
      "Iteration 484, loss = 2.06198430\n",
      "Iteration 485, loss = 2.06188369\n",
      "Iteration 486, loss = 2.06178498\n",
      "Iteration 487, loss = 2.06168246\n",
      "Iteration 488, loss = 2.06157804\n",
      "Iteration 489, loss = 2.06147885\n",
      "Iteration 490, loss = 2.06137252\n",
      "Iteration 491, loss = 2.06126642\n",
      "Iteration 492, loss = 2.06115890\n",
      "Iteration 493, loss = 2.06105161\n",
      "Iteration 494, loss = 2.06094527\n",
      "Iteration 495, loss = 2.06083465\n",
      "Iteration 496, loss = 2.06072474\n",
      "Iteration 497, loss = 2.06061530\n",
      "Iteration 498, loss = 2.06050158\n",
      "Iteration 499, loss = 2.06039023\n",
      "Iteration 500, loss = 2.06027651\n",
      "Iteration 501, loss = 2.06015992\n",
      "Iteration 502, loss = 2.06004620\n",
      "Iteration 503, loss = 2.05993199\n",
      "Iteration 504, loss = 2.05981278\n",
      "Iteration 505, loss = 2.05969119\n",
      "Iteration 506, loss = 2.05957389\n",
      "Iteration 507, loss = 2.05945325\n",
      "Iteration 508, loss = 2.05933022\n",
      "Iteration 509, loss = 2.05920506\n",
      "Iteration 510, loss = 2.05908513\n",
      "Iteration 511, loss = 2.05895925\n",
      "Iteration 512, loss = 2.05883074\n",
      "Iteration 513, loss = 2.05870295\n",
      "Iteration 514, loss = 2.05857682\n",
      "Iteration 515, loss = 2.05844498\n",
      "Iteration 516, loss = 2.05831695\n",
      "Iteration 517, loss = 2.05818629\n",
      "Iteration 518, loss = 2.05805111\n",
      "Iteration 519, loss = 2.05791450\n",
      "Iteration 520, loss = 2.05778122\n",
      "Iteration 521, loss = 2.05764532\n",
      "Iteration 522, loss = 2.05750561\n",
      "Iteration 523, loss = 2.05736947\n",
      "Iteration 524, loss = 2.05723238\n",
      "Iteration 525, loss = 2.05708528\n",
      "Iteration 526, loss = 2.05694437\n",
      "Iteration 527, loss = 2.05680227\n",
      "Iteration 528, loss = 2.05665445\n",
      "Iteration 529, loss = 2.05650830\n",
      "Iteration 530, loss = 2.05636096\n",
      "Iteration 531, loss = 2.05621314\n",
      "Iteration 532, loss = 2.05606461\n",
      "Iteration 533, loss = 2.05591869\n",
      "Iteration 534, loss = 2.05576086\n",
      "Iteration 535, loss = 2.05560541\n",
      "Iteration 536, loss = 2.05545259\n",
      "Iteration 537, loss = 2.05529594\n",
      "Iteration 538, loss = 2.05513763\n",
      "Iteration 539, loss = 2.05497837\n",
      "Iteration 540, loss = 2.05482030\n",
      "Iteration 541, loss = 2.05465674\n",
      "Iteration 542, loss = 2.05449247\n",
      "Iteration 543, loss = 2.05433178\n",
      "Iteration 544, loss = 2.05416131\n",
      "Iteration 545, loss = 2.05399466\n",
      "Iteration 546, loss = 2.05382800\n",
      "Iteration 547, loss = 2.05365443\n",
      "Iteration 548, loss = 2.05348349\n",
      "Iteration 549, loss = 2.05331230\n",
      "Iteration 550, loss = 2.05313253\n",
      "Iteration 551, loss = 2.05295658\n",
      "Iteration 552, loss = 2.05277848\n",
      "Iteration 553, loss = 2.05259371\n",
      "Iteration 554, loss = 2.05241489\n",
      "Iteration 555, loss = 2.05223417\n",
      "Iteration 556, loss = 2.05205321\n",
      "Iteration 557, loss = 2.05187011\n",
      "Iteration 558, loss = 2.05168438\n",
      "Iteration 559, loss = 2.05149865\n",
      "Iteration 560, loss = 2.05131030\n",
      "Iteration 561, loss = 2.05111909\n",
      "Iteration 562, loss = 2.05092525\n",
      "Iteration 563, loss = 2.05072284\n",
      "Iteration 564, loss = 2.05051279\n",
      "Iteration 565, loss = 2.05030036\n",
      "Iteration 566, loss = 2.05007362\n",
      "Iteration 567, loss = 2.04986143\n",
      "Iteration 568, loss = 2.04964948\n",
      "Iteration 569, loss = 2.04944348\n",
      "Iteration 570, loss = 2.04923868\n",
      "Iteration 571, loss = 2.04902577\n",
      "Iteration 572, loss = 2.04881716\n",
      "Iteration 573, loss = 2.04860091\n",
      "Iteration 574, loss = 2.04838848\n",
      "Iteration 575, loss = 2.04817772\n",
      "Iteration 576, loss = 2.04795694\n",
      "Iteration 577, loss = 2.04774261\n",
      "Iteration 578, loss = 2.04752660\n",
      "Iteration 579, loss = 2.04730701\n",
      "Iteration 580, loss = 2.04709339\n",
      "Iteration 581, loss = 2.04687572\n",
      "Iteration 582, loss = 2.04665661\n",
      "Iteration 583, loss = 2.04643631\n",
      "Iteration 584, loss = 2.04621625\n",
      "Iteration 585, loss = 2.04599833\n",
      "Iteration 586, loss = 2.04578447\n",
      "Iteration 587, loss = 2.04556417\n",
      "Iteration 588, loss = 2.04534793\n",
      "Iteration 589, loss = 2.04512620\n",
      "Iteration 590, loss = 2.04490662\n",
      "Iteration 591, loss = 2.04468679\n",
      "Iteration 592, loss = 2.04446197\n",
      "Iteration 593, loss = 2.04423928\n",
      "Iteration 594, loss = 2.04402018\n",
      "Iteration 595, loss = 2.04380012\n",
      "Iteration 596, loss = 2.04357982\n",
      "Iteration 597, loss = 2.04335737\n",
      "Iteration 598, loss = 2.04313374\n",
      "Iteration 599, loss = 2.04291081\n",
      "Iteration 600, loss = 2.04268622\n",
      "Iteration 601, loss = 2.04246330\n",
      "Iteration 602, loss = 2.04223871\n",
      "Iteration 603, loss = 2.04201102\n",
      "Iteration 604, loss = 2.04178095\n",
      "Iteration 605, loss = 2.04155064\n",
      "Iteration 606, loss = 2.04131889\n",
      "Iteration 607, loss = 2.04108763\n",
      "Iteration 608, loss = 2.04085445\n",
      "Iteration 609, loss = 2.04061937\n",
      "Iteration 610, loss = 2.04038644\n",
      "Iteration 611, loss = 2.04015398\n",
      "Iteration 612, loss = 2.03991675\n",
      "Iteration 613, loss = 2.03967738\n",
      "Iteration 614, loss = 2.03943968\n",
      "Iteration 615, loss = 2.03919721\n",
      "Iteration 616, loss = 2.03895712\n",
      "Iteration 617, loss = 2.03872156\n",
      "Iteration 618, loss = 2.03847909\n",
      "Iteration 619, loss = 2.03823924\n",
      "Iteration 620, loss = 2.03799510\n",
      "Iteration 621, loss = 2.03775287\n",
      "Iteration 622, loss = 2.03749490\n",
      "Iteration 623, loss = 2.03723645\n",
      "Iteration 624, loss = 2.03697038\n",
      "Iteration 625, loss = 2.03669834\n",
      "Iteration 626, loss = 2.03642440\n",
      "Iteration 627, loss = 2.03617406\n",
      "Iteration 628, loss = 2.03591609\n",
      "Iteration 629, loss = 2.03565192\n",
      "Iteration 630, loss = 2.03539300\n",
      "Iteration 631, loss = 2.03513336\n",
      "Iteration 632, loss = 2.03487921\n",
      "Iteration 633, loss = 2.03463244\n",
      "Iteration 634, loss = 2.03437924\n",
      "Iteration 635, loss = 2.03411961\n",
      "Iteration 636, loss = 2.03386497\n",
      "Iteration 637, loss = 2.03360987\n",
      "Iteration 638, loss = 2.03336096\n",
      "Iteration 639, loss = 2.03311086\n",
      "Iteration 640, loss = 2.03285933\n",
      "Iteration 641, loss = 2.03261518\n",
      "Iteration 642, loss = 2.03236675\n",
      "Iteration 643, loss = 2.03211069\n",
      "Iteration 644, loss = 2.03185153\n",
      "Iteration 645, loss = 2.03159595\n",
      "Iteration 646, loss = 2.03133702\n",
      "Iteration 647, loss = 2.03107786\n",
      "Iteration 648, loss = 2.03082061\n",
      "Iteration 649, loss = 2.03056288\n",
      "Iteration 650, loss = 2.03031802\n",
      "Iteration 651, loss = 2.03006649\n",
      "Iteration 652, loss = 2.02979827\n",
      "Iteration 653, loss = 2.02953053\n",
      "Iteration 654, loss = 2.02927446\n",
      "Iteration 655, loss = 2.02901983\n",
      "Iteration 656, loss = 2.02876925\n",
      "Iteration 657, loss = 2.02852702\n",
      "Iteration 658, loss = 2.02827883\n",
      "Iteration 659, loss = 2.02803540\n",
      "Iteration 660, loss = 2.02779031\n",
      "Iteration 661, loss = 2.02754521\n",
      "Iteration 662, loss = 2.02729630\n",
      "Iteration 663, loss = 2.02705574\n",
      "Iteration 664, loss = 2.02681971\n",
      "Iteration 665, loss = 2.02657318\n",
      "Iteration 666, loss = 2.02633309\n",
      "Iteration 667, loss = 2.02609229\n",
      "Iteration 668, loss = 2.02585244\n",
      "Iteration 669, loss = 2.02561331\n",
      "Iteration 670, loss = 2.02537084\n",
      "Iteration 671, loss = 2.02512932\n",
      "Iteration 672, loss = 2.02488995\n",
      "Iteration 673, loss = 2.02465224\n",
      "Iteration 674, loss = 2.02441764\n",
      "Iteration 675, loss = 2.02418399\n",
      "Iteration 676, loss = 2.02395058\n",
      "Iteration 677, loss = 2.02371883\n",
      "Iteration 678, loss = 2.02348804\n",
      "Iteration 679, loss = 2.02326202\n",
      "Iteration 680, loss = 2.02302217\n",
      "Iteration 681, loss = 2.02278495\n",
      "Iteration 682, loss = 2.02254868\n",
      "Iteration 683, loss = 2.02231407\n",
      "Iteration 684, loss = 2.02208471\n",
      "Iteration 685, loss = 2.02186537\n",
      "Iteration 686, loss = 2.02164888\n",
      "Iteration 687, loss = 2.02140427\n",
      "Iteration 688, loss = 2.02119207\n",
      "Iteration 689, loss = 2.02096272\n",
      "Iteration 690, loss = 2.02073550\n",
      "Iteration 691, loss = 2.02051187\n",
      "Iteration 692, loss = 2.02028704\n",
      "Iteration 693, loss = 2.02006507\n",
      "Iteration 694, loss = 2.01985979\n",
      "Iteration 695, loss = 2.01962519\n",
      "Iteration 696, loss = 2.01941752\n",
      "Iteration 697, loss = 2.01918697\n",
      "Iteration 698, loss = 2.01896858\n",
      "Iteration 699, loss = 2.01876211\n",
      "Iteration 700, loss = 2.01856470\n",
      "Iteration 701, loss = 2.01834440\n",
      "Iteration 702, loss = 2.01811910\n",
      "Iteration 703, loss = 2.01791930\n",
      "Iteration 704, loss = 2.01769209\n",
      "Iteration 705, loss = 2.01749325\n",
      "Iteration 706, loss = 2.01726699\n",
      "Iteration 707, loss = 2.01707339\n",
      "Iteration 708, loss = 2.01684928\n",
      "Iteration 709, loss = 2.01666737\n",
      "Iteration 710, loss = 2.01645207\n",
      "Iteration 711, loss = 2.01622510\n",
      "Iteration 712, loss = 2.01602077\n",
      "Iteration 713, loss = 2.01581550\n",
      "Iteration 714, loss = 2.01560974\n",
      "Iteration 715, loss = 2.01540112\n",
      "Iteration 716, loss = 2.01518583\n",
      "Iteration 717, loss = 2.01497769\n",
      "Iteration 718, loss = 2.01477194\n",
      "Iteration 719, loss = 2.01457977\n",
      "Iteration 720, loss = 2.01438904\n",
      "Iteration 721, loss = 2.01421165\n",
      "Iteration 722, loss = 2.01399016\n",
      "Iteration 723, loss = 2.01381278\n",
      "Iteration 724, loss = 2.01357770\n",
      "Iteration 725, loss = 2.01337957\n",
      "Iteration 726, loss = 2.01318359\n",
      "Iteration 727, loss = 2.01298761\n",
      "Iteration 728, loss = 2.01279402\n",
      "Iteration 729, loss = 2.01260734\n",
      "Iteration 730, loss = 2.01246095\n",
      "Iteration 731, loss = 2.01222253\n",
      "Iteration 732, loss = 2.01206017\n",
      "Iteration 733, loss = 2.01183915\n",
      "Iteration 734, loss = 2.01167703\n",
      "Iteration 735, loss = 2.01145959\n",
      "Iteration 736, loss = 2.01133037\n",
      "Iteration 737, loss = 2.01109982\n",
      "Iteration 738, loss = 2.01094770\n",
      "Iteration 739, loss = 2.01071477\n",
      "Iteration 740, loss = 2.01054358\n",
      "Iteration 741, loss = 2.01034188\n",
      "Iteration 742, loss = 2.01016259\n",
      "Iteration 743, loss = 2.00998473\n",
      "Iteration 744, loss = 2.00985265\n",
      "Iteration 745, loss = 2.00960898\n",
      "Iteration 746, loss = 2.00943065\n",
      "Iteration 747, loss = 2.00928426\n",
      "Iteration 748, loss = 2.00914741\n",
      "Iteration 749, loss = 2.00888729\n",
      "Iteration 750, loss = 2.00871515\n",
      "Iteration 751, loss = 2.00855279\n",
      "Iteration 752, loss = 2.00835323\n",
      "Iteration 753, loss = 2.00817370\n",
      "Iteration 754, loss = 2.00800133\n",
      "Iteration 755, loss = 2.00782418\n",
      "Iteration 756, loss = 2.00764680\n",
      "Iteration 757, loss = 2.00747442\n",
      "Iteration 758, loss = 2.00729728\n",
      "Iteration 759, loss = 2.00712585\n",
      "Iteration 760, loss = 2.00695205\n",
      "Iteration 761, loss = 2.00679207\n",
      "Iteration 762, loss = 2.00660849\n",
      "Iteration 763, loss = 2.00643730\n",
      "Iteration 764, loss = 2.00627494\n",
      "Iteration 765, loss = 2.00609493\n",
      "Iteration 766, loss = 2.00592303\n",
      "Iteration 767, loss = 2.00575304\n",
      "Iteration 768, loss = 2.00558305\n",
      "Iteration 769, loss = 2.00541782\n",
      "Iteration 770, loss = 2.00524569\n",
      "Iteration 771, loss = 2.00507712\n",
      "Iteration 772, loss = 2.00491595\n",
      "Iteration 773, loss = 2.00474215\n",
      "Iteration 774, loss = 2.00457478\n",
      "Iteration 775, loss = 2.00440812\n",
      "Iteration 776, loss = 2.00424147\n",
      "Iteration 777, loss = 2.00407505\n",
      "Iteration 778, loss = 2.00391078\n",
      "Iteration 779, loss = 2.00377274\n",
      "Iteration 780, loss = 2.00358057\n",
      "Iteration 781, loss = 2.00341964\n",
      "Iteration 782, loss = 2.00326514\n",
      "Iteration 783, loss = 2.00308990\n",
      "Iteration 784, loss = 2.00292349\n",
      "Iteration 785, loss = 2.00276160\n",
      "Iteration 786, loss = 2.00259495\n",
      "Iteration 787, loss = 2.00243545\n",
      "Iteration 788, loss = 2.00227427\n",
      "Iteration 789, loss = 2.00210714\n",
      "Iteration 790, loss = 2.00194454\n",
      "Iteration 791, loss = 2.00178194\n",
      "Iteration 792, loss = 2.00162005\n",
      "Iteration 793, loss = 2.00145888\n",
      "Iteration 794, loss = 2.00129700\n",
      "Iteration 795, loss = 2.00113511\n",
      "Iteration 796, loss = 2.00097370\n",
      "Iteration 797, loss = 2.00081325\n",
      "Iteration 798, loss = 2.00065184\n",
      "Iteration 799, loss = 2.00049114\n",
      "Iteration 800, loss = 2.00033045\n",
      "Iteration 801, loss = 2.00016999\n",
      "Iteration 802, loss = 2.00000978\n",
      "Iteration 803, loss = 1.99984932\n",
      "Iteration 804, loss = 1.99968922\n",
      "Iteration 805, loss = 1.99952924\n",
      "Iteration 806, loss = 1.99936914\n",
      "Iteration 807, loss = 1.99920952\n",
      "Iteration 808, loss = 1.99906778\n",
      "Iteration 809, loss = 1.99889529\n",
      "Iteration 810, loss = 1.99873877\n",
      "Iteration 811, loss = 1.99858189\n",
      "Iteration 812, loss = 1.99841917\n",
      "Iteration 813, loss = 1.99826109\n",
      "Iteration 814, loss = 1.99809325\n",
      "Iteration 815, loss = 1.99793363\n",
      "Iteration 816, loss = 1.99777246\n",
      "Iteration 817, loss = 1.99761295\n",
      "Iteration 818, loss = 1.99745727\n",
      "Iteration 819, loss = 1.99731076\n",
      "Iteration 820, loss = 1.99713564\n",
      "Iteration 821, loss = 1.99697447\n",
      "Iteration 822, loss = 1.99681389\n",
      "Iteration 823, loss = 1.99665666\n",
      "Iteration 824, loss = 1.99650633\n",
      "Iteration 825, loss = 1.99634635\n",
      "Iteration 826, loss = 1.99617767\n",
      "Iteration 827, loss = 1.99602473\n",
      "Iteration 828, loss = 1.99585521\n",
      "Iteration 829, loss = 1.99569297\n",
      "Iteration 830, loss = 1.99553299\n",
      "Iteration 831, loss = 1.99538422\n",
      "Iteration 832, loss = 1.99522436\n",
      "Iteration 833, loss = 1.99504495\n",
      "Iteration 834, loss = 1.99487603\n",
      "Iteration 835, loss = 1.99470878\n",
      "Iteration 836, loss = 1.99455643\n",
      "Iteration 837, loss = 1.99438715\n",
      "Iteration 838, loss = 1.99422693\n",
      "Iteration 839, loss = 1.99407554\n",
      "Iteration 840, loss = 1.99390578\n",
      "Iteration 841, loss = 1.99373484\n",
      "Iteration 842, loss = 1.99358332\n",
      "Iteration 843, loss = 1.99341619\n",
      "Iteration 844, loss = 1.99325085\n",
      "Iteration 845, loss = 1.99309289\n",
      "Iteration 846, loss = 1.99292099\n",
      "Iteration 847, loss = 1.99276650\n",
      "Iteration 848, loss = 1.99259543\n",
      "Iteration 849, loss = 1.99243617\n",
      "Iteration 850, loss = 1.99226475\n",
      "Iteration 851, loss = 1.99211478\n",
      "Iteration 852, loss = 1.99194527\n",
      "Iteration 853, loss = 1.99177957\n",
      "Iteration 854, loss = 1.99161506\n",
      "Iteration 855, loss = 1.99144971\n",
      "Iteration 856, loss = 1.99127412\n",
      "Iteration 857, loss = 1.99110818\n",
      "Iteration 858, loss = 1.99094188\n",
      "Iteration 859, loss = 1.99079883\n",
      "Iteration 860, loss = 1.99061763\n",
      "Iteration 861, loss = 1.99045229\n",
      "Iteration 862, loss = 1.99027359\n",
      "Iteration 863, loss = 1.99011362\n",
      "Iteration 864, loss = 1.98995674\n",
      "Iteration 865, loss = 1.98977470\n",
      "Iteration 866, loss = 1.98961532\n",
      "Iteration 867, loss = 1.98944044\n",
      "Iteration 868, loss = 1.98927748\n",
      "Iteration 869, loss = 1.98909307\n",
      "Iteration 870, loss = 1.98892272\n",
      "Iteration 871, loss = 1.98875260\n",
      "Iteration 872, loss = 1.98858750\n",
      "Iteration 873, loss = 1.98841608\n",
      "Iteration 874, loss = 1.98826051\n",
      "Iteration 875, loss = 1.98806870\n",
      "Iteration 876, loss = 1.98790467\n",
      "Iteration 877, loss = 1.98772240\n",
      "Iteration 878, loss = 1.98756242\n",
      "Iteration 879, loss = 1.98737264\n",
      "Iteration 880, loss = 1.98719275\n",
      "Iteration 881, loss = 1.98702157\n",
      "Iteration 882, loss = 1.98687136\n",
      "Iteration 883, loss = 1.98666883\n",
      "Iteration 884, loss = 1.98649085\n",
      "Iteration 885, loss = 1.98631084\n",
      "Iteration 886, loss = 1.98614287\n",
      "Iteration 887, loss = 1.98597777\n",
      "Iteration 888, loss = 1.98578310\n",
      "Iteration 889, loss = 1.98560894\n",
      "Iteration 890, loss = 1.98542142\n",
      "Iteration 891, loss = 1.98524785\n",
      "Iteration 892, loss = 1.98506582\n",
      "Iteration 893, loss = 1.98488295\n",
      "Iteration 894, loss = 1.98469818\n",
      "Iteration 895, loss = 1.98452115\n",
      "Iteration 896, loss = 1.98433757\n",
      "Iteration 897, loss = 1.98415101\n",
      "Iteration 898, loss = 1.98396027\n",
      "Iteration 899, loss = 1.98377240\n",
      "Iteration 900, loss = 1.98358655\n",
      "Iteration 901, loss = 1.98340034\n",
      "Iteration 902, loss = 1.98321378\n",
      "Iteration 903, loss = 1.98302698\n",
      "Iteration 904, loss = 1.98283720\n",
      "Iteration 905, loss = 1.98265004\n",
      "Iteration 906, loss = 1.98246002\n",
      "Iteration 907, loss = 1.98226869\n",
      "Iteration 908, loss = 1.98207843\n",
      "Iteration 909, loss = 1.98188639\n",
      "Iteration 910, loss = 1.98169374\n",
      "Iteration 911, loss = 1.98150003\n",
      "Iteration 912, loss = 1.98130655\n",
      "Iteration 913, loss = 1.98111653\n",
      "Iteration 914, loss = 1.98093867\n",
      "Iteration 915, loss = 1.98075318\n",
      "Iteration 916, loss = 1.98056078\n",
      "Iteration 917, loss = 1.98034775\n",
      "Iteration 918, loss = 1.98013735\n",
      "Iteration 919, loss = 1.97993612\n",
      "Iteration 920, loss = 1.97973502\n",
      "Iteration 921, loss = 1.97953379\n",
      "Iteration 922, loss = 1.97933316\n",
      "Iteration 923, loss = 1.97913241\n",
      "Iteration 924, loss = 1.97894609\n",
      "Iteration 925, loss = 1.97875023\n",
      "Iteration 926, loss = 1.97852778\n",
      "Iteration 927, loss = 1.97831929\n",
      "Iteration 928, loss = 1.97811151\n",
      "Iteration 929, loss = 1.97790444\n",
      "Iteration 930, loss = 1.97770441\n",
      "Iteration 931, loss = 1.97749901\n",
      "Iteration 932, loss = 1.97728300\n",
      "Iteration 933, loss = 1.97706854\n",
      "Iteration 934, loss = 1.97685552\n",
      "Iteration 935, loss = 1.97664320\n",
      "Iteration 936, loss = 1.97642660\n",
      "Iteration 937, loss = 1.97621059\n",
      "Iteration 938, loss = 1.97599721\n",
      "Iteration 939, loss = 1.97577727\n",
      "Iteration 940, loss = 1.97556496\n",
      "Iteration 941, loss = 1.97534227\n",
      "Iteration 942, loss = 1.97511995\n",
      "Iteration 943, loss = 1.97490132\n",
      "Iteration 944, loss = 1.97468078\n",
      "Iteration 945, loss = 1.97446287\n",
      "Iteration 946, loss = 1.97426939\n",
      "Iteration 947, loss = 1.97404706\n",
      "Iteration 948, loss = 1.97386336\n",
      "Iteration 949, loss = 1.97360706\n",
      "Iteration 950, loss = 1.97340333\n",
      "Iteration 951, loss = 1.97312272\n",
      "Iteration 952, loss = 1.97289026\n",
      "Iteration 953, loss = 1.97265756\n",
      "Iteration 954, loss = 1.97242570\n",
      "Iteration 955, loss = 1.97219443\n",
      "Iteration 956, loss = 1.97196734\n",
      "Iteration 957, loss = 1.97173548\n",
      "Iteration 958, loss = 1.97150397\n",
      "Iteration 959, loss = 1.97127128\n",
      "Iteration 960, loss = 1.97107112\n",
      "Iteration 961, loss = 1.97090673\n",
      "Iteration 962, loss = 1.97059691\n",
      "Iteration 963, loss = 1.97042239\n",
      "Iteration 964, loss = 1.97013175\n",
      "Iteration 965, loss = 1.96994340\n",
      "Iteration 966, loss = 1.96966100\n",
      "Iteration 967, loss = 1.96944213\n",
      "Iteration 968, loss = 1.96916711\n",
      "Iteration 969, loss = 1.96895456\n",
      "Iteration 970, loss = 1.96868765\n",
      "Iteration 971, loss = 1.96849310\n",
      "Iteration 972, loss = 1.96821344\n",
      "Iteration 973, loss = 1.96811342\n",
      "Iteration 974, loss = 1.96775544\n",
      "Iteration 975, loss = 1.96759033\n",
      "Iteration 976, loss = 1.96727610\n",
      "Iteration 977, loss = 1.96715093\n",
      "Iteration 978, loss = 1.96677828\n",
      "Iteration 979, loss = 1.96666920\n",
      "Iteration 980, loss = 1.96628261\n",
      "Iteration 981, loss = 1.96614909\n",
      "Iteration 982, loss = 1.96572983\n",
      "Iteration 983, loss = 1.96548939\n",
      "Iteration 984, loss = 1.96523988\n",
      "Iteration 985, loss = 1.96499157\n",
      "Iteration 986, loss = 1.96471524\n",
      "Iteration 987, loss = 1.96448314\n",
      "Iteration 988, loss = 1.96419835\n",
      "Iteration 989, loss = 1.96397018\n",
      "Iteration 990, loss = 1.96370184\n",
      "Iteration 991, loss = 1.96346986\n",
      "Iteration 992, loss = 1.96319973\n",
      "Iteration 993, loss = 1.96303892\n",
      "Iteration 994, loss = 1.96270227\n",
      "Iteration 995, loss = 1.96251667\n",
      "Iteration 996, loss = 1.96217752\n",
      "Iteration 997, loss = 1.96190286\n",
      "Iteration 998, loss = 1.96166563\n",
      "Iteration 999, loss = 1.96149659\n",
      "Iteration 1000, loss = 1.96114683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slime/Workspace/Vietnamese-Alphabet-Pronunciation/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(feature_vectors, labels)\n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mmatplotlib.lines.Line2D\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7176e8c22df0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m]\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mFigure\u001b[0m\u001b[39m size 64\u001b[0m\u001b[1;36m0x480\u001b[0m\u001b[39m with \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m Axes\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.loss_curve_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.13750699\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mfloat32\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 10\n",
    "label = id2label(labels[idx])\n",
    "proba = model.predict_proba(np.expand_dims(feature_vectors[idx], 0))\n",
    "proba[:, labels[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mnp.int64\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.13750699\u001b[0m, \u001b[1;36m0.14352863\u001b[0m, \u001b[1;36m0.16309036\u001b[0m, \u001b[1;36m0.07813117\u001b[0m, \u001b[1;36m0.08005571\u001b[0m,\n",
       "        \u001b[1;36m0.13545252\u001b[0m, \u001b[1;36m0.14164065\u001b[0m, \u001b[1;36m0.12059403\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mfloat32\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[idx], model.predict_proba(np.expand_dims(feature_vectors[idx], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 141 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 141 samples in 0.151s...\n",
      "[t-SNE] Computed conditional probabilities for sample 141 / 141\n",
      "[t-SNE] Mean sigma: 1.872073\n",
      "[t-SNE] Computed conditional probabilities in 0.013s\n",
      "[t-SNE] Iteration 50: error = 46.7683372, gradient norm = 0.3864654 (50 iterations in 0.026s)\n",
      "[t-SNE] Iteration 100: error = 46.5584602, gradient norm = 0.3027618 (50 iterations in 0.024s)\n",
      "[t-SNE] Iteration 150: error = 46.5196457, gradient norm = 0.3674369 (50 iterations in 0.021s)\n",
      "[t-SNE] Iteration 200: error = 47.1398926, gradient norm = 0.3375542 (50 iterations in 0.018s)\n",
      "[t-SNE] Iteration 250: error = 47.5185127, gradient norm = 0.2950214 (50 iterations in 0.017s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 47.518513\n",
      "[t-SNE] Iteration 300: error = 0.0832369, gradient norm = 0.0021899 (50 iterations in 0.015s)\n",
      "[t-SNE] Iteration 350: error = 0.0720903, gradient norm = 0.0033564 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 400: error = 0.0680919, gradient norm = 0.0011113 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 450: error = 0.0630041, gradient norm = 0.0041647 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 500: error = 0.0600588, gradient norm = 0.0007744 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 550: error = 0.0602528, gradient norm = 0.0005850 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 600: error = 0.0599507, gradient norm = 0.0006644 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 650: error = 0.0597827, gradient norm = 0.0002625 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 700: error = 0.0598701, gradient norm = 0.0005767 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 750: error = 0.0599416, gradient norm = 0.0004216 (50 iterations in 0.012s)\n",
      "[t-SNE] Iteration 800: error = 0.0598796, gradient norm = 0.0002056 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 850: error = 0.0602451, gradient norm = 0.0002051 (50 iterations in 0.014s)\n",
      "[t-SNE] Iteration 900: error = 0.0601412, gradient norm = 0.0001642 (50 iterations in 0.012s)\n",
      "[t-SNE] Iteration 950: error = 0.0600969, gradient norm = 0.0001637 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 1000: error = 0.0600852, gradient norm = 0.0001733 (50 iterations in 0.013s)\n",
      "[t-SNE] Iteration 1000: did not make any progress during the last 300 episodes. Finished.\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.060085\n"
     ]
    }
   ],
   "source": [
    "model = TSNE(\n",
    "    n_components=2,\n",
    "    verbose=2,\n",
    ").fit_transform(np.asarray(feature_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "color=E<br>0=%{x}<br>1=%{y}<extra></extra>",
         "legendgroup": "E",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "E",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -4.462593078613281,
          -5.718559741973877,
          8.552145957946777,
          7.965466022491455,
          8.85966968536377,
          -5.5490827560424805,
          8.221944808959961,
          8.019464492797852,
          -7.114896774291992,
          -1.523110032081604,
          -0.8551042675971985,
          2.0008349418640137,
          -0.9445919990539551,
          -0.46267250180244446,
          7.97909688949585,
          1.3050293922424316
         ],
         "xaxis": "x",
         "y": [
          10.163504600524902,
          3.5547196865081787,
          -10.922426223754883,
          -6.717822551727295,
          -6.704460144042969,
          4.257227420806885,
          -7.317089557647705,
          -6.260434150695801,
          11.041399002075195,
          2.0190584659576416,
          2.316671848297119,
          0.1064893901348114,
          2.1815383434295654,
          2.588026523590088,
          -11.243355751037598,
          -1.0142431259155273
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "color=H<br>0=%{x}<br>1=%{y}<extra></extra>",
         "legendgroup": "H",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "H",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -2.1264407634735107,
          -8.31136417388916,
          8.066184043884277,
          5.632533550262451,
          7.972151279449463,
          7.5735554695129395,
          8.30974006652832,
          -1.9478026628494263,
          -1.4132527112960815,
          -1.6355215311050415,
          -1.1490387916564941,
          -1.5191822052001953,
          8.273012161254883,
          -7.070497035980225,
          1.7873117923736572,
          0.5839179754257202
         ],
         "xaxis": "x",
         "y": [
          0.6238529086112976,
          8.510293960571289,
          -10.998722076416016,
          -10.614845275878906,
          -8.263385772705078,
          -7.391170978546143,
          -10.640666007995605,
          1.6249046325683594,
          1.0426069498062134,
          0.768989622592926,
          1.6383190155029297,
          1.080769419670105,
          -10.312472343444824,
          11.039131164550781,
          -0.454130083322525,
          -1.5468697547912598
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "color=L<br>0=%{x}<br>1=%{y}<extra></extra>",
         "legendgroup": "L",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "L",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0.8300184607505798,
          1.5192203521728516,
          -7.144660949707031,
          8.661892890930176,
          7.93108606338501,
          -8.832476615905762,
          8.355002403259277,
          -6.295861721038818,
          -8.555068969726562,
          -8.085322380065918,
          -1.976330041885376,
          -8.438966751098633,
          -7.933152198791504,
          -8.111778259277344,
          -8.441913604736328,
          -2.4973278045654297,
          1.3357315063476562,
          -7.820453643798828,
          1.2596439123153687
         ],
         "xaxis": "x",
         "y": [
          -1.280747890472412,
          0.18277807533740997,
          6.931103229522705,
          -7.745090961456299,
          -6.827324867248535,
          6.7715349197387695,
          -6.888545513153076,
          11.17778205871582,
          6.744157314300537,
          6.906557083129883,
          2.4325153827667236,
          8.44970703125,
          8.127632141113281,
          8.215737342834473,
          6.674228668212891,
          9.214153289794922,
          -0.7008522748947144,
          6.426886081695557,
          0.02023482508957386
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "color=N<br>0=%{x}<br>1=%{y}<extra></extra>",
         "legendgroup": "N",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "N",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0.8964110016822815,
          -9.082353591918945,
          -7.070047378540039,
          -8.54681396484375,
          -1.294609785079956,
          -1.9438236951828003,
          -2.8747012615203857,
          -8.526611328125,
          -7.714609146118164,
          -8.438325881958008,
          -4.311788082122803,
          -7.729232311248779,
          8.243585586547852,
          -7.015707969665527,
          2.2393133640289307,
          8.875762939453125,
          -5.1138153076171875,
          -8.255715370178223,
          1.3975589275360107
         ],
         "xaxis": "x",
         "y": [
          0.06289751082658768,
          7.764119625091553,
          11.036495208740234,
          6.798133373260498,
          1.6486663818359375,
          1.1309086084365845,
          9.45161247253418,
          8.401686668395996,
          7.00800085067749,
          10.105147361755371,
          10.09422492980957,
          8.46139144897461,
          -10.207650184631348,
          11.104440689086914,
          -0.21654368937015533,
          -7.35414981842041,
          4.35062313079834,
          6.681641101837158,
          -0.14631609618663788
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "color=U<br>0=%{x}<br>1=%{y}<extra></extra>",
         "legendgroup": "U",
         "marker": {
          "color": "#FFA15A",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "U",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -3.2949090003967285,
          7.41121768951416,
          9.289444923400879,
          7.339970111846924,
          -5.574623107910156,
          -8.561410903930664,
          -6.350888252258301,
          -2.1828906536102295,
          -9.340414047241211,
          8.092679023742676,
          -1.0698174238204956,
          0.7772377133369446,
          -8.834775924682617,
          5.5766119956970215,
          -1.8871181011199951,
          9.149158477783203,
          6.811863422393799,
          -9.594389915466309
         ],
         "xaxis": "x",
         "y": [
          9.662303924560547,
          -10.692083358764648,
          -10.954487800598145,
          -10.009961128234863,
          4.418612480163574,
          10.023749351501465,
          11.181543350219727,
          1.5572689771652222,
          6.268389701843262,
          -6.668188095092773,
          0.9616146683692932,
          -1.0493017435073853,
          6.6444292068481445,
          -10.543631553649902,
          1.7557055950164795,
          -7.814540386199951,
          -6.623916149139404,
          7.836234092712402
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "color=V<br>0=%{x}<br>1=%{y}<extra></extra>",
         "legendgroup": "V",
         "marker": {
          "color": "#19d3f3",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "V",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -8.564330101013184,
          8.924592971801758,
          -6.308046340942383,
          -8.685544967651367,
          8.632957458496094,
          8.40919017791748,
          -1.3406379222869873,
          4.918798923492432,
          -8.371496200561523,
          -8.963375091552734,
          -1.0793026685714722,
          0.9321990013122559,
          -1.3789277076721191,
          -5.686003684997559,
          -2.471658945083618,
          8.876884460449219,
          8.163363456726074
         ],
         "xaxis": "x",
         "y": [
          6.714150905609131,
          -7.340729713439941,
          11.183218002319336,
          8.001850128173828,
          -7.892700672149658,
          -8.616697311401367,
          0.5690076351165771,
          -9.849102020263672,
          10.01278305053711,
          8.178933143615723,
          1.2629928588867188,
          -0.2625274658203125,
          0.328857421875,
          4.182673454284668,
          9.196802139282227,
          -6.649296283721924,
          -7.450383186340332
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "color=i<br>0=%{x}<br>1=%{y}<extra></extra>",
         "legendgroup": "i",
         "marker": {
          "color": "#FF6692",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "i",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8.116060256958008,
          -6.987208843231201,
          0.8717164993286133,
          7.437556743621826,
          7.47499418258667,
          0.7340506911277771,
          -6.45367956161499,
          -0.5512341260910034,
          -8.32308578491211,
          -5.923893928527832,
          7.607247829437256,
          -5.634761333465576,
          8.64161205291748,
          -3.256744861602783,
          -5.870922565460205,
          7.607641220092773,
          -3.1022748947143555,
          -1.6073261499404907,
          8.281729698181152
         ],
         "xaxis": "x",
         "y": [
          -10.482343673706055,
          11.108972549438477,
          -0.5793361663818359,
          -10.191308975219727,
          -10.255702018737793,
          -0.6247668266296387,
          3.853971481323242,
          1.7747844457626343,
          6.150224685668945,
          3.4320433139801025,
          -7.83440637588501,
          3.3687808513641357,
          -8.31960391998291,
          9.644142150878906,
          4.112820148468018,
          -10.587797164916992,
          9.573671340942383,
          1.8767244815826416,
          -8.173776626586914
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "color=<br>0=%{x}<br>1=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#B6E880",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          5.524937629699707,
          -8.905294418334961,
          1.3596726655960083,
          7.217900276184082,
          -8.466229438781738,
          -4.912326812744141,
          4.928699016571045,
          -5.23826789855957,
          1.7149218320846558,
          1.535119891166687,
          1.976408839225769,
          7.6379570960998535,
          0.48306459188461304,
          7.7463459968566895,
          -2.5064308643341064,
          7.669597625732422,
          -5.206426620483398
         ],
         "xaxis": "x",
         "y": [
          -10.462645530700684,
          7.910830974578857,
          0.6826736330986023,
          -7.878358840942383,
          10.061782836914062,
          4.444578647613525,
          -9.857564926147461,
          4.0356950759887695,
          1.7635830640792847,
          -0.334105521440506,
          -1.143860936164856,
          -11.104999542236328,
          -0.7019068002700806,
          -7.682229042053223,
          9.221638679504395,
          -10.303288459777832,
          4.237860679626465
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "color"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "0"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "1"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(model, x=0, y=1, color=labels)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'5'\u001b[0m, \u001b[32m'0'\u001b[0m, \u001b[32m'4'\u001b[0m, \u001b[33m...\u001b[0m, \u001b[32m'4'\u001b[0m, \u001b[32m'5'\u001b[0m, \u001b[32m'6'\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mobject\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;36m0.9999999900000001\u001b[0m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.15930423, 0.1652451 , 0.17497283, 0.0614966 , 0.05916306,\n",
    "        0.11112186, 0.1471671 , 0.12152921])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
