import io
from pathlib import Path

import numpy as np
import streamlit as st
from audiorecorder import audiorecorder

from src.models import load_model, predict_score
from src.ui.menu import Routes
from src.ui.utils import (
    add_vertical_space,
    config_page,
    unique_audio_filename,
    unique_session_id,
    upload_file,
)

config_page(Routes.COURSE)

LESSONS = [
    {"title": "Ch·ªØ c√°i E", "id": "E"},
    {"title": "Ch·ªØ c√°i H", "id": "H"},
    {"title": "Ch·ªØ c√°i I", "id": "I"},
    {"title": "Ch·ªØ c√°i L", "id": "L"},
    {"title": "Ch·ªØ c√°i N", "id": "N"},
    {"title": "Ch·ªØ c√°i ∆†", "id": "∆†"},
    {"title": "Ch·ªØ c√°i U", "id": "U"},
    {"title": "Ch·ªØ c√°i V", "id": "V"},
]


@st.fragment
def show_lesson(lesson):
    lesson_title = lesson["title"]
    lesson_id = lesson["id"]
    lesson_video_file = (
        Path(__file__).parents[1] / "assets" / "videos" / f"{lesson_id}.mov"
    )

    st.subheader(lesson_title)
    st.video(lesson_video_file)

    add_vertical_space(1)

    st.subheader("Ch·∫•m ƒëi·ªÉm")
    st.markdown("Sau khi h·ªçc xong b√†i h·ªçc, h√£y ƒë·ªçc l·∫°i ch·ªØ c√°i ƒë√≥ ƒë·ªÉ h·ªá th·ªëng ch·∫•m ƒëi·ªÉm")
    audio = audiorecorder(
        "",  # "·∫§n ƒë·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m",
        "",  # "·∫§n ƒë·ªÉ d·ª´ng l·∫°i",
        key=lesson_id,
    )

    if len(audio) > 0:
        st.info(
            "H√£y gi√∫p t·ªõ check l·∫°i ph√°t √¢m xem ƒë√£ ƒë√∫ng v√† r√µ r√†ng ch∆∞a nh√© ·∫°! N·∫øu ch∆∞a ƒë∆∞·ª£c th√¨ h√£y ghi √¢m l·∫°i gi√∫p t·ªõ nha ·∫°!!",
            icon="‚ÑπÔ∏è",
        )
        st.audio(audio.export().read())

    if st.button(label="Ch·∫•m ƒëi·ªÉm", type="primary"):
        if len(audio) > 0:
            with st.spinner("Evaluating..."):
                score = None
                waveform = np.asarray(
                    audio.set_frame_rate(16000).get_array_of_samples()
                ).T.astype(np.float32)

                try:
                    score = predict_score(model, waveform, actual_label=lesson_id)
                    if score > 3.8:
                        st.info("B·∫°n ph√°t √¢m r·∫•t t·ªët!")
                    else:
                        st.warning(
                            "B·∫°n c·∫ßn c·∫£i thi·ªán th√™m. Xem l·∫°i video v√† ph√°t √¢m l·∫°i nh√©!"
                        )
                except:
                    st.error(
                        "Gi√∫p t·ªõ thu √¢m l·∫°i nha, b·∫°n nh·ªõ ph√°t √¢m to r√µ nh√©", icon="üö®"
                    )

                # upload to Dropbox
                audio_buffer = io.BytesIO()
                audio.export(audio_buffer, format="wav", parameters=["-ar", str(16000)])
                upload_file(
                    audio_buffer.getvalue(),
                    unique_audio_filename(
                        st.session_state["session_id"],
                        lesson_id,
                        score,
                    ),
                )
        else:
            st.error("Ch∆∞a ƒë∆∞·ª£c r·ªìi, gi√∫p t·ªõ thu √¢m l·∫°i nha", icon="üö®")


if "session_id" not in st.session_state:
    st.session_state["session_id"] = unique_session_id()

model = load_model()

st.sidebar.divider()
lesson = st.sidebar.radio(
    "B√†i h·ªçc",
    options=range(len(LESSONS)),
    index=None,
    format_func=lambda option: LESSONS[option]["title"],
    key="lessons",
)

add_vertical_space(1)

if lesson is None:
    st.info(
        "Ch·ªçn b√†i h·ªçc ·ªü b√™n tr√°i.",
        icon="‚ÑπÔ∏è",
    )
else:
    show_lesson(LESSONS[lesson])
